{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4f31be",
   "metadata": {},
   "source": [
    "# Source Localization Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f048dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generated_closed = np.load('./data/training/eyes-closed-64ch.npy')\n",
    "# generated_open = np.load('./data/training/eyes-open-64ch.npy')\n",
    "\n",
    "# ch_names = ['EEG {0}'.format(i) for i in range(64)] \n",
    "# ch_types = ['eeg' for _ in range(64)]\n",
    "# info = mne.create_info(ch_names=ch_names, sfreq=160, ch_types=ch_types)\n",
    "\n",
    "# generated_closed_mne = []\n",
    "# for i in range(len(generated_closed)):\n",
    "#     generated_closed_mne.append(mne.io.RawArray(generated_closed[i], info))\n",
    "\n",
    "# generated_open_mne = []\n",
    "# for i in range(len(generated_open)):\n",
    "#     generated_open_mne.append(mne.io.RawArray(generated_open[i], info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b63962",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "len(data) (1) does not match len(info[\"ch_names\"]) (64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m ch_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m)]\n\u001b[0;32m     25\u001b[0m info \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mcreate_info(ch_names\u001b[38;5;241m=\u001b[39mch_names, sfreq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160.0\u001b[39m, ch_types\u001b[38;5;241m=\u001b[39mch_types)\n\u001b[1;32m---> 26\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRawArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/training/training-closed-64ch-normalized.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m ten_twenty_montage \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mchannels\u001b[38;5;241m.\u001b[39mmake_standard_montage(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard_1020\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m new_names \u001b[38;5;241m=\u001b[39m ten_twenty_montage\u001b[38;5;241m.\u001b[39mch_names[:\u001b[38;5;28mlen\u001b[39m(raw\u001b[38;5;241m.\u001b[39mch_names)]\n",
      "File \u001b[1;32m<decorator-gen-246>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, data, info, first_samp, copy, verbose)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\array\\array.py:68\u001b[0m, in \u001b[0;36mRawArray.__init__\u001b[1;34m(self, data, info, first_samp, copy, verbose)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be a 2D array of shape (n_channels, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples), got shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (data\u001b[38;5;241m.\u001b[39mshape,)\n\u001b[0;32m     66\u001b[0m     )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(data) (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) does not match \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen(info[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]) (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mch_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnchan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: len(data) (1) does not match len(info[\"ch_names\"]) (64)"
     ]
    }
   ],
   "source": [
    "# %pip install nibabel\n",
    "# %pip install pyvistaqt\n",
    "# %pip install ipywidgets\n",
    "# %pip install ipyevents\n",
    "# %pip install trame\n",
    "# %pip install trame-vuetify\n",
    "# %pip install trame-vtk\n",
    "# %pip install pyvista\n",
    "\n",
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from mne import setup_source_space\n",
    "from mne import make_forward_solution\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne import compute_raw_covariance\n",
    "\n",
    "# Creating a MNE Raw object\n",
    "ch_names = ['EEG {0}'.format(i) for i in range(64)] \n",
    "ch_types = ['eeg' for _ in range(64)]\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=160.0, ch_types=ch_types)\n",
    "raw = mne.io.RawArray(np.load(\"./data/training/training-closed-64ch-normalized.npy\")[2], info)\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "new_names = ten_twenty_montage.ch_names[:len(raw.ch_names)]\n",
    "mapping = dict(zip(raw.ch_names, new_names)) # Create a dictionary mapping old names to new names then rename\n",
    "raw.rename_channels(mapping)\n",
    "raw.set_montage(ten_twenty_montage)\n",
    "\n",
    "raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "# Use pre-processing methods in MNE, for instance: filter the signal\n",
    "# raw.filter(l_freq=1, h_freq=None)\n",
    "\n",
    "# Setting the subjects_dir path\n",
    "subjects_dir = str(mne.datasets.sample.data_path()) + '/subjects'\n",
    "\n",
    "# Setting up the source space\n",
    "src = setup_source_space('fsaverage', spacing='oct6', add_dist=False, subjects_dir=subjects_dir)\n",
    "\n",
    "# Making the forward model\n",
    "fsaverage = mne.datasets.fetch_fsaverage(verbose=True)\n",
    "bem_dir = os.path.join(fsaverage, 'bem')\n",
    "bem_fname = os.path.join(bem_dir, 'fsaverage-5120-5120-5120-bem-sol.fif')\n",
    "bem_sol = mne.read_bem_solution(bem_fname, verbose=True)\n",
    "\n",
    "# Now pass the bem_sol to the make_forward_solution function\n",
    "fwd = make_forward_solution(raw.info, trans=None, src=src, bem=bem_sol, meg=False, eeg=True)\n",
    "\n",
    "# Compute the inverse solution\n",
    "noise_cov = compute_raw_covariance(raw, tmin=0.0, tmax=9760 / raw.info['sfreq']) # Compute the covariance on a segment of the raw data\n",
    "inv = make_inverse_operator(raw.info, fwd, noise_cov, loose=0.2, depth=0.8)\n",
    "lambda2 = 1.0 / 9.0  # this is equivalent to using a signal-to-noise ratio of 3\n",
    "method = 'dSPM'  # use dSPM method (could also be MNE or sLORETA)\n",
    "events = mne.make_fixed_length_events(raw, duration=2.0)  # Here duration is in sec.\n",
    "epochs = mne.Epochs(raw, events, tmin=0, tmax=60, baseline=None, reject=None)  # Here tmin and tmax are in sec.\n",
    "evoked = epochs.average()\n",
    "\n",
    "stc = apply_inverse(evoked, inv, lambda2, method)\n",
    "stc.plot(\n",
    "    subject='fsaverage',\n",
    "    hemi='both',  # Specify 'both' to show both hemispheres\n",
    "    surface='inflated',\n",
    "    subjects_dir=subjects_dir,\n",
    "    time_viewer=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4ee094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 9760)\n"
     ]
    }
   ],
   "source": [
    "open = np.load(\"./data/training/eyes-closed-64ch.npy\")[2]\n",
    "\n",
    "\n",
    "print(np.shape(open))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a764fc-2ae8-4795-9aa7-7a9f1d03292d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
