{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to showcase what this dataset looks like. This notebook contains how to interact with the dataset as well as some of the helper functions this repo uses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Figure Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a couple of settings for the dataset and the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the name we'll set for the file\n",
    "fname = 'motor_imagery.npz'\n",
    "# This is where we download the dataset from\n",
    "url = \"https://osf.io/ksqv8/download\"\n",
    "\n",
    "# Check if the file is already there\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"!!! Failed to download data !!!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)\n",
    "\n",
    "# Figure settings\n",
    "rcParams['figure.figsize'] = [20, 4]\n",
    "rcParams['font.size'] = 15\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process():\n",
    "    def __init__():\n",
    "        \"\"\"\n",
    "        This class is used to preprocess the data.\n",
    "        The input is a dict with a key 'V' containing the voltage data.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def preprocess(data):\n",
    "        V = data['V'].astype('float32')\n",
    "        b, a = signal.butter(3, [50], btype='high', fs=1000)\n",
    "        V = signal.filtfilt(b, a, V, 0)\n",
    "        V = np.abs(V)**2\n",
    "        b, a = signal.butter(3, [10], btype='low', fs=1000)\n",
    "        V = signal.filtfilt(b, a, V, 0)\n",
    "        V = V/V.mean(0)\n",
    "        return V\n",
    "\n",
    "class plots():\n",
    "    def __init__():\n",
    "        \"\"\"\n",
    "        For plotting the dataset\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def singlechannel1(data, channel, trange, title=''):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        if title:\n",
    "            plt.suptitle(title, fontsize=20)\n",
    "        plt.plot(trange, data[:,channel])\n",
    "        plt.title('ch%d'%channel)\n",
    "        plt.xticks([0, 1000, 2000])\n",
    "        plt.ylim([0, 4])\n",
    "\n",
    "    def singlechannel2(data, data2, channel, trange, title=''):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        if title:\n",
    "            plt.suptitle(title, fontsize=20)\n",
    "        plt.plot(trange, data[:,channel])\n",
    "        plt.plot(trange, data2[:,channel])\n",
    "        plt.title('ch%d'%channel)\n",
    "        plt.xticks([0, 1000, 2000])\n",
    "        plt.ylim([0, 4])\n",
    "\n",
    "    def all_channels1(data, trange, title=''):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        if title:\n",
    "            plt.suptitle(title, fontsize=20)\n",
    "        for j in range(46):\n",
    "            ax = plt.subplot(5,10,j+1)\n",
    "            plt.plot(trange, data[:,j])\n",
    "            plt.title('ch%d'%j)\n",
    "            plt.xticks([0, 1000, 2000])\n",
    "            plt.ylim([0, 4])\n",
    "\n",
    "    def all_channels2(data, data2, trange, title=''):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        if title:\n",
    "            plt.suptitle(title, fontsize=20)\n",
    "        for j in range(46):\n",
    "            ax = plt.subplot(5,10,j+1)\n",
    "            plt.plot(trange, data[:,j])\n",
    "            plt.plot(trange, data2[:,j])\n",
    "            plt.title('ch%d'%j)\n",
    "            plt.xticks([0, 1000, 2000])\n",
    "            plt.ylim([0, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset this repo uses is an ECoG dataset that contains imaginary and real movement of a couple of different stimuli. For this project, we primarily focus on imagining moving the tongue and imagining moving the hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat = np.load(fname, allow_pickle=True)['dat']\n",
    "\n",
    "# select just one of the recordings here. 11 is nice because it has some neurons in vis ctx.\n",
    "dat1 = alldat[0][0]\n",
    "dat2 = alldat[0][1]\n",
    "\n",
    "print(dat1.keys())\n",
    "print(dat2.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `dat['V']`: continuous voltage data (time by channels)\n",
    "* `dat['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  \n",
    "* `dat['t_on']`: time of stimulus onset in data samples\n",
    "* `dat['t_off']`: time of stimulus offset, always 400 samples after `t_on`\n",
    "* `dat['stim_id`]: identity of stimulus (11 = tongue, 12 = hand), real or imaginary stimulus\n",
    "* `dat['scale_uv']`: scale factor to multiply the data values to get to microvolts (uV). \n",
    "* `dat['locs`]`: 3D electrode positions on the brain surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nimare import utils\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "locs = dat1['locs']\n",
    "view = plotting.view_markers(utils.tal2mni(locs),\n",
    "                             marker_labels=['%d'%k for k in np.arange(locs.shape[0])],\n",
    "                             marker_color='purple',\n",
    "                             marker_size=5)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick way to get broadband power in time-varying windows\n",
    "from scipy import signal\n",
    "\n",
    "# pick subject 0 and experiment 0 (real movements)\n",
    "dat1 = alldat[0][0]\n",
    "\n",
    "# V is the voltage data\n",
    "V = dat1['V'].astype('float32')\n",
    "\n",
    "# high-pass filter above 50 Hz\n",
    "b, a = signal.butter(3, [50], btype='high', fs=1000)\n",
    "V = signal.filtfilt(b, a, V, 0)\n",
    "\n",
    "# compute smooth envelope of this signal = approx power\n",
    "V = np.abs(V)**2\n",
    "b, a = signal.butter(3, [10], btype='low', fs=1000)\n",
    "V = signal.filtfilt(b, a, V, 0)\n",
    "\n",
    "# normalize each channel so its mean power is 1\n",
    "V = V/V.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the broadband power across all tongue and hand trials\n",
    "nt, nchan = V.shape\n",
    "nstim = len(dat1['t_on'])\n",
    "\n",
    "trange = np.arange(0, 2000)\n",
    "ts = dat1['t_on'][:, np.newaxis] + trange\n",
    "V_epochs = np.reshape(V[ts, :], (nstim, 2000, nchan))\n",
    "\n",
    "V_tongue = (V_epochs[dat1['stim_id'] == 11]).mean(0)\n",
    "V_hand = (V_epochs[dat1['stim_id'] == 12]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the electrodes that distinguish tongue from hand movements\n",
    "# note the behaviors happen some time after the visual cue\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for j in range(46):\n",
    "  ax = plt.subplot(5, 10, j+1)\n",
    "  #plt.plot(trange, V_tongue[:, j])\n",
    "  plt.plot(trange, V_hand[:, j])\n",
    "  plt.title('ch%d'%j)\n",
    "  plt.xticks([0, 1000, 2000])\n",
    "  plt.ylim([0, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at all the trials for electrode 20 that has a good response to hand movements\n",
    "# we will sort trials by stimulus id\n",
    "plt.subplot(1, 3, 1)\n",
    "isort = np.argsort(dat1['stim_id'])\n",
    "plt.imshow(V_epochs[isort, :, 20].astype('float32'),\n",
    "           aspect='auto',\n",
    "           vmax=7, vmin=0,\n",
    "           cmap='magma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrode 42 seems to respond to tongue movements\n",
    "isort = np.argsort(dat1['stim_id'])\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(V_epochs[isort, :, 42].astype('float32'),\n",
    "           aspect='auto',\n",
    "           vmax=7, vmin=0,\n",
    "           cmap='magma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options are 'test' and 'real'. Test is smaller version of the dataset, real is the full dataset.\n",
    "mode = 'test'\n",
    "\n",
    "# 12 is the hand, 11 is the tongue\n",
    "desired_stim = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "DataLoad = np.load(fname, allow_pickle=True)['dat']\n",
    "# Print the data\n",
    "type(DataLoad), len(DataLoad), DataLoad.shape, DataLoad[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we'll keep all the processed data\n",
    "realV = {}\n",
    "imagV = {}\n",
    "\n",
    "# This is where we'll hold all the metadata\n",
    "realMeta = {}\n",
    "imagineMeta = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the keys we'll be filtering for in the dataset\n",
    "desiredKeys = ['t_off', 'stim_id', 't_on', 'V', 'scale_uv', 'locs', 'srate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'test':\n",
    "    length_of_data = 1\n",
    "elif mode == 'real':\n",
    "    length_of_data = len(DataLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trange = np.arange(0, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length_of_data):\n",
    "    print(f\"Sample rate of participant (real) {i}: {DataLoad[i][0]['srate']}\")\n",
    "    print(f\"Sample rate of participant (imagine) {i}: {DataLoad[i][1]['srate']}\")\n",
    "    \n",
    "    x = process.preprocess(DataLoad[i][0])\n",
    "    nt, nchan = x.shape\n",
    "    nstim = len(DataLoad[i][0]['t_on'])\n",
    "    ts = DataLoad[i][0]['t_on'][:, np.newaxis] + trange\n",
    "    V_epochs = np.reshape(x[ts, :], (nstim, 2000, nchan))\n",
    "    V_epochs = V_epochs[DataLoad[i][0]['stim_id']==desired_stim]\n",
    "    print(V_epochs.shape)\n",
    "    realV[i] = V_epochs\n",
    "    realMeta[i] = {key: DataLoad[i][0][key] for key in desiredKeys}\n",
    "\n",
    "    y = process.preprocess(DataLoad[i][1])\n",
    "    nt, nchan = y.shape\n",
    "    nstim = len(DataLoad[i][1]['t_on'])\n",
    "    ts = DataLoad[i][1]['t_on'][:, np.newaxis] + trange\n",
    "    V_epochs = np.reshape(y[ts, :], (nstim, 2000, nchan))\n",
    "    V_epochs = V_epochs[DataLoad[i][1]['stim_id']==desired_stim]\n",
    "    print(V_epochs.shape)\n",
    "    imagV[i] = V_epochs\n",
    "    imagineMeta[i] = {key: DataLoad[i][1][key] for key in desiredKeys}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realV contains the preprocessed and properly filtered data for the real movement trials\n",
    "\n",
    "- realV\n",
    "\n",
    "realSet contains the metadata for the real movement trials\n",
    "\n",
    "- realMeta\n",
    "\n",
    "imagineV contains the preprocessed and properly filtered data for the imagined movement trials\n",
    "\n",
    "- imagV\n",
    "\n",
    "imagineSet contains the metadata for the imagined movement trials\n",
    "\n",
    "- imagineMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trange, realV[0][0, :])\n",
    "plt.show()\n",
    "plt.plot(trange, realV[0][29, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length_of_data):\n",
    "    plots.all_channels1(realV[i][0], trange, f'Real Movement: Participant {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length_of_data):\n",
    "    plots.all_channels1(imagV[i][0], trange, f'Imagined Movement: Participant {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(length_of_data):\n",
    "    plots.all_channels1(realV[i][0] - imagV[i][0], trange, f'Real Movement - Imaged Movement: Participant {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.all_channels2(realV[0][0], imagV[0][0], trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.singlechannel1(realV[0][0], 0, trange)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGDataset(realV[0])\n",
    "plt.plot(trange, EEG.__getitem__(1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
