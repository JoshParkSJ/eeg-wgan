{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning with MNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEfine the time window for epochs around the events\n",
    "tmin, tmax = -1., 4.\n",
    "\n",
    "# Dictionary that maps event names to their corresponding event codes.\n",
    "# Event codes are numeric identifiers that are used to label different type of events or triggers in EEG/MEG data.\n",
    "event_id = {'hands': 2, 'feet': 3}\n",
    "\n",
    "# This is the subject we choose to study. Can be in the range of 1-109 (inclusive)\n",
    "subject = 1\n",
    "\n",
    "# This is the run we choose to study. Can be in the range of 1-14 (inclusive)\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| run | task |\n",
    "| --- | --- |\n",
    "| 1 | baseline, eyes open |\n",
    "| 2 | baseline, eyes closed |\n",
    "| 3, 7, 11 | Motor execution: left vs right hand | \n",
    "| 4, 8, 12 | Motor imagery: left vs right hand |\n",
    "| 5, 9, 13 | Motor execution: hands vs feet |\n",
    "| 6, 10, 14 | Motor imagery: hands vs feet |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in the subject and runs you're interested in\n",
    "raw_fnames = mne.datasets.eegbci.load_data(subject, runs, './', verbose=False)\n",
    "\n",
    "# Loads in the data file then reads and concatenates the data into the `raw` object\n",
    "raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True, verbose=False) for f in raw_fnames])\n",
    "\n",
    "# Set channel names in the EEG data\n",
    "mne.datasets.eegbci.standardize(raw)\n",
    "\n",
    "# This creates an info object that represents the 10/05 electrode positions \n",
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "\n",
    "# Attaches the montage to the raw data\n",
    "raw.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This applies a bandpass filter (finite impulse response) to the data and avoids filtering data near the edge\n",
    "raw.filter(7.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "# This line extracts information from annotations present in the raw data.\n",
    "# Annotations are labels attached to specific points in the data and usually represent events or important time segments.\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "# This line selects specific channel types from the raw data\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    raw, # Datase\n",
    "    events, # Events\n",
    "    event_id, # Event ID\n",
    "    t_min, # Start time\n",
    "    t_max, # End time\n",
    "    proj=True, # Apply SSP projection vectors\n",
    "    picks=picks, # Channels to include\n",
    "    baseline=None, # Baseline interval\n",
    "    preload=True, # Load data into memory\n",
    ")\n",
    "\n",
    "# This creates a new epochs object by copying the original epochs object and cropping the time interval from 1 to 2 seconds.\n",
    "epochs_train = epochs.copy().crop(tmin=1.0, tmax=2.0)\n",
    "\n",
    "# This creates a numpy array that contains the labels for each epoch. \n",
    "# The labels are stored in the last column of the events array. \n",
    "# The labels are stored as integers, but we want them to be 0 and 1. \n",
    "# We can subtract 2 from the labels to get the desired values.\n",
    "labels = epochs.events[:, -1] - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot(n_channels=1, n_epochs=1, scalings='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "# Keeps track of an empty list called scores for the cross-validation procedure\n",
    "scores = []\n",
    "# This extracts the data as a numpy array from the MNE object\n",
    "epochs_data = epochs.get_data()\n",
    "# This extracts the data from the epochs_train object\n",
    "epochs_data_train = epochs_train.get_data()\n",
    "# This line creates a cross-validation (CV) generator using the ShuffleSplit method\n",
    "cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "# This line creates the actual cross-validation splits using the splits method of the CV generator\n",
    "cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "csp = mne.decoding.CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "clf = Pipeline([(\"CSP\", csp), (\"LDA\", lda)])\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=None)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1.0 - class_balance)\n",
    "print(\n",
    "    \"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores), class_balance)\n",
    ")\n",
    "\n",
    "# This code above sets up a classification pipeline that includes CSP for feature extraction and LDA as the classifier\n",
    "# It then performs cross-validation using the pipeline and prints the average classification accuracy and chance level of classification accuracy.\n",
    "# This code aims to evaluate the performance of the classifier on the given EEG data and the corresponding labels using cross-validation\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "csp.plot_patterns(epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = raw.info[\"sfreq\"]\n",
    "w_length = int(sfreq * 0.5)  # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = csp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "    X_test = csp.transform(epochs_data_train[test_idx])\n",
    "\n",
    "    # fit classifier\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = csp.transform(epochs_data[test_idx][:, :, n : (n + w_length)])\n",
    "        score_this_window.append(lda.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.0) / sfreq + epochs.tmin\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label=\"Score\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.title(\"Classification score over time\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
