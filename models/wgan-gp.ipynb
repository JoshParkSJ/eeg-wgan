{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-23T20:13:47.949334Z","iopub.status.busy":"2023-12-23T20:13:47.948835Z","iopub.status.idle":"2023-12-23T20:14:25.374905Z","shell.execute_reply":"2023-12-23T20:14:25.373601Z","shell.execute_reply.started":"2023-12-23T20:13:47.949299Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["hello GPU\n","Using 2 GPUs\n","INFO: Restoring checkpoint for D...\n","INFO: Restoring checkpoint for G...\n","INFO: Starting training from global step 32989...\n","INFO: Saving checkpoints from keyboard interrupt...\n","INFO: Training Ended.\n"]}],"source":["\n","\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch import autograd\n","from torch.nn.parameter import Parameter\n","from scipy.signal import welch\n","from torch.autograd import Variable\n","\n","\"\"\"\n","Loss functions definitions.\n","\"\"\"\n","import torch\n","import torch.nn.functional as F\n","\n","\n","\n","def _bce_loss_with_logits(output, labels, **kwargs):\n","    r\"\"\"\n","    Wrapper for BCE loss with logits.\n","    \"\"\"\n","    return F.binary_cross_entropy_with_logits(output, labels, **kwargs)\n","\n","\n","def minimax_loss_gen(output_fake, real_label_val=1.0, **kwargs):\n","    r\"\"\"\n","    Standard minimax loss for GANs through the BCE Loss with logits fn.\n","\n","    Args:\n","        output (Tensor): Discriminator output logits.\n","        labels (Tensor): Labels for computing cross entropy.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    # Produce real labels so G is rewarded if D is fooled\n","    real_labels = torch.full((output_fake.shape[0], 1),\n","                             real_label_val,\n","                             device=output_fake.device)\n","\n","    loss = _bce_loss_with_logits(output_fake, real_labels, **kwargs)\n","\n","    return loss\n","\n","\n","def minimax_loss_dis(output_fake,\n","                     output_real,\n","                     real_label_val=1.0,\n","                     fake_label_val=0.0,\n","                     **kwargs):\n","    r\"\"\"\n","    Standard minimax loss for GANs through the BCE Loss with logits fn.\n","\n","    Args:\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","        output_real (Tensor): Discriminator output logits for real signals.\n","        real_label_val (int): Label for real signals.\n","        fake_label_val (int): Label for fake signals.\n","        device (torch.device): Torch device object for sending created data.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    # Produce real and fake labels.\n","    fake_labels = torch.full((output_fake.shape[0], 1),\n","                             fake_label_val,\n","                             device=output_fake.device)\n","    real_labels = torch.full((output_real.shape[0], 1),\n","                             real_label_val,\n","                             device=output_real.device)\n","\n","    # FF, compute loss and backprop D\n","    errD_fake = _bce_loss_with_logits(output=output_fake,\n","                                      labels=fake_labels,\n","                                      **kwargs)\n","\n","    errD_real = _bce_loss_with_logits(output=output_real,\n","                                      labels=real_labels,\n","                                      **kwargs)\n","\n","    # Compute cumulative error\n","    loss = errD_real + errD_fake\n","\n","    return loss\n","\n","\n","def ns_loss_gen(output_fake):\n","    r\"\"\"\n","    Non-saturating loss for generator.\n","\n","    Args:\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    output_fake = torch.sigmoid(output_fake)\n","\n","    return -torch.mean(torch.log(output_fake + 1e-8))\n","\n","\n","def wasserstein_loss_dis(output_real, output_fake):\n","    r\"\"\"\n","    Computes the wasserstein loss for the discriminator.\n","\n","    Args:\n","        output_real (Tensor): Discriminator output logits for real signals.\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    loss = -1.0 * output_real.mean() + output_fake.mean()\n","\n","    return loss\n","\n","\n","def wasserstein_loss_gen(output_fake):\n","    r\"\"\"\n","    Computes the wasserstein loss for generator.\n","\n","    Args:\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    loss = -output_fake.mean()\n","\n","    return loss\n","\n","\n","def hinge_loss_dis(output_fake, output_real):\n","    r\"\"\"\n","    Hinge loss for discriminator.\n","\n","    Args:\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","        output_real (Tensor): Discriminator output logits for real signals.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    loss = F.relu(1.0 - output_real).mean() + \\\n","           F.relu(1.0 + output_fake).mean()\n","\n","    return loss\n","\n","\n","def hinge_loss_gen(output_fake):\n","    r\"\"\"\n","    Hinge loss for generator.\n","\n","    Args:\n","        output_fake (Tensor): Discriminator output logits for fake signals.\n","\n","    Returns:\n","        Tensor: A scalar tensor loss output.\n","    \"\"\"\n","    loss = -output_fake.mean()\n","\n","    return loss\n","\n","\n","import os\n","import re\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","\n","\"\"\"\n","Implementation of the Logger object for performing training logging and visualisation.\n","\"\"\"\n","import os\n","\n","import numpy as np\n","import torch\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import utils as vutils\n","\n","\n","class Logger:\n","    \"\"\"\n","    Writes summaries and visualises training progress.\n","\n","    Attributes:\n","        log_dir (str): The path to store logging information.\n","        num_steps (int): Total number of training iterations.\n","        dataset_size (int): The number of examples in the dataset.\n","        device (Device): Torch device object to send data to.\n","        flush_secs (int): Number of seconds before flushing summaries to disk.\n","        writers (dict): A dictionary of tensorboard writers with keys as metric names.\n","        num_epochs (int): The number of epochs, for extra information.\n","    \"\"\"\n","    def __init__(self,\n","                 log_dir,\n","                 num_steps,\n","                 dataset_size,\n","                 device,\n","                 flush_secs=120,\n","                 **kwargs):\n","        self.log_dir = log_dir\n","        self.num_steps = num_steps\n","        self.dataset_size = dataset_size\n","        self.flush_secs = flush_secs\n","        self.num_epochs = self._get_epoch(num_steps)\n","        self.device = device\n","        self.writers = {}\n","\n","        # Create log directory if haven't already\n","        if not os.path.exists(self.log_dir):\n","            os.makedirs(self.log_dir)\n","\n","    def _get_epoch(self, steps):\n","        \"\"\"\n","        Helper function for getting epoch.\n","        \"\"\"\n","        return max(int(steps / self.dataset_size), 1)\n","\n","    def _build_writer(self, metric):\n","        writer = SummaryWriter(log_dir=os.path.join(self.log_dir, 'data',\n","                                                    metric),\n","                               flush_secs=self.flush_secs)\n","\n","        return writer\n","\n","    def write_summaries(self, log_data, global_step):\n","        \"\"\"\n","        Tasks appropriate writers to write the summaries in tensorboard. Creates additional\n","        writers for summary writing if there are new scalars to log in log_data.\n","\n","        Args:\n","            log_data (MetricLog): Dict-like object to collect log data for TB writing.\n","            global_step (int): Global step variable for syncing logs.\n","\n","        Returns:\n","            None\n","        \"\"\"\n","        for metric, data in log_data.items():\n","            if metric not in self.writers:\n","                self.writers[metric] = self._build_writer(metric)\n","\n","            # Write with a group name if it exists\n","            name = log_data.get_group_name(metric) or metric\n","            self.writers[metric].add_scalar(name,\n","                                            log_data[metric],\n","                                            global_step=global_step)\n","\n","    def close_writers(self):\n","        \"\"\"\n","        Closes all writers.\n","        \"\"\"\n","        for metric in self.writers:\n","            self.writers[metric].close()\n","\n","    def print_log(self, global_step, log_data, time_taken):\n","        \"\"\"\n","        Formats the string to print to stdout based on training information.\n","\n","        Args:\n","            log_data (MetricLog): Dict-like object to collect log data for TB writing.\n","            global_step (int): Global step variable for syncing logs.\n","            time_taken (float): Time taken for one training iteration.\n","\n","        Returns:\n","            str: String to be printed to stdout.\n","        \"\"\"\n","        # Basic information\n","        log_to_show = [\n","            \"INFO: [Epoch {:d}/{:d}][Global Step: {:d}/{:d}]\".format(\n","                self._get_epoch(global_step), self.num_epochs, global_step,\n","                self.num_steps)\n","        ]\n","\n","        # Display GAN information as fed from user.\n","        GAN_info = [\"\"]\n","        metrics = sorted(log_data.keys())\n","\n","        for metric in metrics:\n","            GAN_info.append('{}: {}'.format(metric, log_data[metric]))\n","\n","        # Add train step time information\n","        GAN_info.append(\"({:.4f} sec/idx)\".format(time_taken))\n","\n","        # Accumulate to log\n","        log_to_show.append(\"\\n| \".join(GAN_info))\n","\n","        # Finally print the output\n","        ret = \" \".join(log_to_show)\n","        print(ret)\n","\n","        return ret\n","\n","    def _get_fixed_noise(self, nz, num_signals, output_dir=None):\n","        \"\"\"\n","        Produce the fixed gaussian noise vectors used across all models\n","        for consistency.\n","        \"\"\"\n","        if output_dir is None:\n","            output_dir = os.path.join(self.log_dir, 'viz')\n","\n","        if not os.path.exists(output_dir):\n","            os.makedirs(output_dir)\n","        output_file = os.path.join(output_dir,\n","                                   'fixed_noise_nz_{}.pth'.format(nz))\n","\n","        if os.path.exists(output_file):\n","            noise = torch.load(output_file)\n","\n","        else:\n","            noise = torch.randn((num_signals, nz))\n","            torch.save(noise, output_file)\n","\n","        return noise.to(self.device)\n","\n","    def _get_fixed_labels(self, num_signals, num_classes):\n","        \"\"\"\n","        Produces fixed class labels for generating fixed signals.\n","        \"\"\"\n","        labels = np.array([i % num_classes for i in range(num_signals)])\n","        labels = torch.from_numpy(labels).to(self.device)\n","\n","        return labels\n","\n","    def vis_signals(self, netG, global_step, num_signals=64):\n","        \"\"\"\n","        Produce visualisations of the G(z), one fixed and one random.\n","\n","        Args:\n","            netG (Module): Generator model object for producing signals.\n","            global_step (int): Global step variable for syncing logs.\n","            num_signals (int): The number of signals to visualise.\n","\n","        Returns:\n","            None\n","        \"\"\"\n","        img_dir = os.path.join(self.log_dir, 'signals')\n","        if not os.path.exists(img_dir):\n","            os.makedirs(img_dir)\n","\n","        with torch.no_grad():\n","            # Generate random signals\n","            noise = torch.randn((num_signals, netG.nz), device=self.device)\n","            fake_signals = netG(noise).detach().cpu()\n","\n","            # Generate fixed random signals\n","            fixed_noise = self._get_fixed_noise(nz=netG.nz,\n","                                                num_signals=num_signals)\n","\n","            if hasattr(netG, 'num_classes') and netG.num_classes > 0:\n","                fixed_labels = self._get_fixed_labels(num_signals,\n","                                                      netG.num_classes)\n","                fixed_fake_signals = netG(fixed_noise,\n","                                         fixed_labels).detach().cpu()\n","            else:\n","                fixed_fake_signals = netG(fixed_noise).detach().cpu()\n","\n","            # Map name to results\n","            signals_dict = {\n","                'fixed_fake': fixed_fake_signals,\n","                'fake': fake_signals\n","            }\n","\n","            # Visualise all results\n","            for name, signals in signals_dict.items():\n","                signals_viz = vutils.make_grid(signals,\n","                                              padding=2,\n","                                              normalize=True)\n","\n","                vutils.save_signal(signals_viz,\n","                                  '{}/{}_samples_step_{}.png'.format(\n","                                      img_dir, name, global_step),\n","                                  normalize=True)\n","\n","                if 'img' not in self.writers:\n","                    self.writers['img'] = self._build_writer('img')\n","\n","                self.writers['img'].add_signal('{}_vis'.format(name),\n","                                              signals_viz,\n","                                              global_step=global_step)\n","\"\"\"\n","MetricLog object for intelligently logging data to display them more intuitively.\n","\"\"\"\n","\n","\n","class MetricLog:\n","    \"\"\"\n","    A dictionary-like object that logs data, and includes an extra dict to map the metrics\n","    to its group name, if any, and the corresponding precision to print out.\n","\n","    Attributes:\n","        metrics_dict (dict): A dictionary mapping to another dict containing\n","            the corresponding value, precision, and the group this metric belongs to.\n","    \"\"\"\n","    def __init__(self, **kwargs):\n","        self.metrics_dict = {}\n","\n","    def add_metric(self, name, value, group=None, precision=4):\n","        \"\"\"\n","        Logs metric to internal dict, but with an additional option\n","        of grouping certain metrics together.\n","\n","        Args:\n","            name (str): Name of metric to log.\n","            value (Tensor/Float): Value of the metric to log.\n","            group (str): Name of the group to classify different metrics together.\n","            precision (int): The number of floating point precision to represent the value.\n","\n","        Returns:\n","            None\n","        \"\"\"\n","        # Grab tensor values only\n","        try:\n","            value = value.item()\n","        except AttributeError:\n","            value = value\n","\n","        self.metrics_dict[name] = dict(value=value,\n","                                       group=group,\n","                                       precision=precision)\n","\n","    def __getitem__(self, key):\n","        return round(self.metrics_dict[key]['value'],\n","                     self.metrics_dict[key]['precision'])\n","\n","    def get_group_name(self, name):\n","        \"\"\"\n","        Obtains the group name of a particular metric. For example, errD and errG\n","        which represents the discriminator/generator losses could fall under a\n","        group name called \"loss\".\n","\n","        Args:\n","            name (str): The name of the metric to retrieve group name.\n","\n","        Returns:\n","            str: A string representing the group name of the metric.\n","        \"\"\"\n","        return self.metrics_dict[name]['group']\n","\n","    def keys(self):\n","        \"\"\"\n","        Dict like functionality for retrieving keys.\n","        \"\"\"\n","        return self.metrics_dict.keys()\n","\n","    def items(self):\n","        \"\"\"\n","        Dict like functionality for retrieving items.\n","        \"\"\"\n","        return self.metrics_dict.items()\n","\"\"\"\n","Implementation of a specific learning rate scheduler for GANs.\n","\"\"\"\n","\n","\n","class LRScheduler:\n","    \"\"\"\n","    Learning rate scheduler for training GANs. Supports GAN specific LR scheduling\n","    policies, such as the linear decay policy using in SN-GAN paper as based on the\n","    original chainer implementation. However, one could safely ignore this class\n","    and instead use the official PyTorch scheduler wrappers around a optimizer\n","    for other scheduling policies.\n","\n","    Attributes:\n","        lr_decay (str): The learning rate decay policy to use.\n","        optD (Optimizer): Torch optimizer object for discriminator.\n","        optG (Optimizer): Torch optimizer object for generator.\n","        num_steps (int): The number of training iterations.\n","        lr_D (float): The initial learning rate of optD.\n","        lr_G (float): The initial learning rate of optG.\n","    \"\"\"\n","    def __init__(self,\n","                 lr_decay,\n","                 optD,\n","                 optG,\n","                 num_steps,\n","                 start_step=0,\n","                 **kwargs):\n","        if lr_decay not in [None, 'None', 'linear']:\n","            raise NotImplementedError(\n","                \"lr_decay {} is not currently supported.\")\n","\n","        self.lr_decay = lr_decay\n","        self.optD = optD\n","        self.optG = optG\n","        self.num_steps = num_steps\n","        self.start_step = start_step\n","\n","        # Cache the initial learning rate for uses later\n","        self.lr_D = optD.param_groups[0]['lr']\n","        self.lr_G = optG.param_groups[0]['lr']\n","\n","    def linear_decay(self, optimizer, global_step, lr_value_range,\n","                     lr_step_range):\n","        \"\"\"\n","        Performs linear decay of the optimizer learning rate based on the number of global\n","        steps taken. Follows SNGAN's chainer implementation of linear decay, as seen in the\n","        chainer references:\n","        https://docs.chainer.org/en/stable/reference/generated/chainer.training.extensions.LinearShift.html\n","        https://github.com/chainer/chainer/blob/v6.2.0/chainer/training/extensions/linear_shift.py#L66\n","\n","        Note: assumes that the optimizer has only one parameter group to update!\n","\n","        Args:\n","            optimizer (Optimizer): Torch optimizer object to update learning rate.\n","            global_step (int): The current global step of the training.\n","            lr_value_range (tuple): A tuple of floats (x,y) to decrease from x to y.\n","            lr_step_range (tuple): A tuple of ints (i, j) to start decreasing\n","                when global_step > i, and until j.\n","\n","        Returns:\n","            float: Float representing the new updated learning rate.\n","        \"\"\"\n","        # Compute the new learning rate\n","        v1, v2 = lr_value_range\n","        s1, s2 = lr_step_range\n","\n","        if global_step <= s1:\n","            updated_lr = v1\n","\n","        elif global_step >= s2:\n","            updated_lr = v2\n","\n","        else:\n","            scale_factor = (global_step - s1) / (s2 - s1)\n","            updated_lr = v1 + scale_factor * (v2 - v1)\n","\n","        # Update the learning rate\n","        optimizer.param_groups[0]['lr'] = updated_lr\n","\n","        return updated_lr\n","\n","    def step(self, log_data, global_step):\n","        \"\"\"\n","        Takes a step for updating learning rate and updates the input log_data\n","        with the current status.\n","\n","        Args:\n","            log_data (MetricLog): Object for logging the updated learning rate metric.\n","            global_step (int): The current global step of the training.\n","\n","        Returns:\n","            MetricLog: MetricLog object containing the updated learning rate at the current global step.\n","        \"\"\"\n","        if self.lr_decay == \"linear\":\n","            lr_D = self.linear_decay(optimizer=self.optD,\n","                                     global_step=global_step,\n","                                     lr_value_range=(self.lr_D, 0.0),\n","                                     lr_step_range=(self.start_step,\n","                                                    self.num_steps))\n","\n","            lr_G = self.linear_decay(optimizer=self.optG,\n","                                     global_step=global_step,\n","                                     lr_value_range=(self.lr_G, 0.0),\n","                                     lr_step_range=(self.start_step,\n","                                                    self.num_steps))\n","\n","        elif self.lr_decay in [None, \"None\"]:\n","            lr_D = self.lr_D\n","            lr_G = self.lr_G\n","\n","        # Update metrics log\n","        log_data.add_metric('lr_D', lr_D, group='lr', precision=6)\n","        log_data.add_metric('lr_G', lr_G, group='lr', precision=6)\n","\n","        return log_data\n","\n","\"\"\"\n","Script for common utility functions.\n","\"\"\"\n","import json\n","import os\n","\n","import numpy as np\n","import torch\n","from skimage import io\n","\n","\n","def write_to_json(dict_to_write, output_file):\n","    \"\"\"\n","    Outputs a given dictionary as a JSON file with indents.\n","\n","    Args:\n","        dict_to_write (dict): Input dictionary to output.\n","        output_file (str): File path to write the dictionary.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    with open(output_file, 'w') as file:\n","        json.dump(dict_to_write, file, indent=4)\n","\n","\n","def load_from_json(json_file):\n","    \"\"\"\n","    Loads a JSON file as a dictionary and return it.\n","\n","    Args:\n","        json_file (str): Input JSON file to read.\n","\n","    Returns:\n","        dict: Dictionary loaded from the JSON file.\n","    \"\"\"\n","    with open(json_file, 'r') as file:\n","        return json.load(file)\n","\n","\n","def save_tensor_image(x, output_file):\n","    \"\"\"\n","    Saves an input image tensor as some numpy array, useful for tests.\n","\n","    Args:\n","        x (Tensor): A 3D tensor image of shape (3, H, W).\n","        output_file (str): The output image file to save the tensor.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    folder = os.path.dirname(output_file)\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)\n","\n","    x = x.permute(1, 2, 0).numpy()\n","    io.imsave(output_file, x)\n","\n","\n","def load_images(n=1, size=32):\n","    \"\"\"\n","    Load n image tensors with some fake labels.\n","\n","    Args:\n","        n (int): Number of random images to load.\n","        size (int): Spatial size of random image.\n","\n","    Returns:\n","        Tensor: Random images of shape (n, 3, size, size) and 0-valued labels.\n","    \"\"\"\n","    images = torch.randn(n, 3, size, size)\n","    labels = torch.from_numpy(np.array([0 * n]))\n","\n","    return images, labels\n","\n","class Trainer:\n","    \"\"\"\n","    Trainer object for constructing the GAN training pipeline.\n","\n","    Attributes:\n","        netD (Module): Torch discriminator model.\n","        netG (Module): Torch generator model.\n","        optD (Optimizer): Torch optimizer object for discriminator.\n","        optG (Optimizer): Torch optimizer object for generator.\n","        dataloader (DataLoader): Torch object for loading data from a dataset object.\n","        num_steps (int): The number of training iterations.\n","        n_dis (int): Number of discriminator update steps per generator training step.\n","        lr_decay (str): The learning rate decay policy to use.\n","        log_dir (str): The path to storing logging information and checkpoints.\n","        device (Device): Torch device object to send model/data to.\n","        logger (Logger): Logger object for visualising training information.\n","        scheduler (LRScheduler): GAN training specific learning rate scheduler object.\n","        params (dict): Dictionary of training hyperparameters.\n","        netD_ckpt_file (str): Custom checkpoint file to restore discriminator from.\n","        netG_ckpt_file (str): Custom checkpoint file to restore generator from.\n","        print_steps (int): Number of training steps before printing training info to stdout.\n","        vis_steps (int): Number of training steps before visualising images with TensorBoard.\n","        flush_secs (int): Number of seconds before flushing summaries to disk.\n","        log_steps (int): Number of training steps before writing summaries to TensorBoard.\n","        save_steps (int): Number of training steps bfeore checkpointing.\n","    \"\"\"\n","    def __init__(self,\n","                 netD,\n","                 netG,\n","                 optD,\n","                 optG,\n","                 dataloader,\n","                 num_steps,\n","                 log_dir='./log',\n","                 n_dis=1,\n","                 lr_decay=None,\n","                 device=None,\n","                 netG_ckpt_file=None,\n","                 netD_ckpt_file=None,\n","                 print_steps=1,\n","                 vis_steps=500,\n","                 log_steps=50,\n","                 save_steps=5000,\n","                 flush_secs=30):\n","        # Input values checks\n","        ints_to_check = {\n","            'num_steps': num_steps,\n","            'n_dis': n_dis,\n","            'print_steps': print_steps,\n","            'vis_steps': vis_steps,\n","            'log_steps': log_steps,\n","            'save_steps': save_steps,\n","            'flush_secs': flush_secs\n","        }\n","        for name, var in ints_to_check.items():\n","            if var < 1:\n","                raise ValueError('{} must be at least 1 but got {}.'.format(\n","                    name, var))\n","\n","        self.netD = netD\n","        self.netG = netG\n","        self.optD = optD\n","        self.optG = optG\n","        self.n_dis = n_dis\n","        self.lr_decay = lr_decay\n","        self.dataloader = dataloader\n","        self.num_steps = num_steps\n","        self.device = device\n","        self.log_dir = log_dir\n","        self.netG_ckpt_file = netG_ckpt_file\n","        self.netD_ckpt_file = netD_ckpt_file\n","        self.print_steps = print_steps\n","        self.vis_steps = vis_steps\n","        self.log_steps = log_steps\n","        self.save_steps = save_steps\n","        self.errG = []\n","        self.errD = []\n","\n","        if not os.path.exists(self.log_dir):\n","            os.makedirs(self.log_dir)\n","\n","        # Training helper objects\n","        self.logger = Logger(log_dir=self.log_dir,\n","                                    num_steps=self.num_steps,\n","                                    dataset_size=len(self.dataloader),\n","                                    flush_secs=flush_secs,\n","                                    device=self.device)\n","\n","        self.scheduler = LRScheduler(lr_decay=self.lr_decay,\n","                                               optD=self.optD,\n","                                               optG=self.optG,\n","                                               num_steps=self.num_steps)\n","\n","        # Obtain custom or latest checkpoint files\n","        if self.netG_ckpt_file:\n","            self.netG_ckpt_dir = os.path.dirname(netG_ckpt_file)\n","            self.netG_ckpt_file = netG_ckpt_file\n","        else:\n","            self.netG_ckpt_dir = os.path.join(self.log_dir, 'checkpoints',\n","                                              'netG')\n","            self.netG_ckpt_file = self._get_latest_checkpoint(\n","                self.netG_ckpt_dir)  # can be None\n","\n","        if self.netD_ckpt_file:\n","            self.netD_ckpt_dir = os.path.dirname(netD_ckpt_file)\n","            self.netD_ckpt_file = netD_ckpt_file\n","        else:\n","            self.netD_ckpt_dir = os.path.join(self.log_dir, 'checkpoints',\n","                                              'netD')\n","            self.netD_ckpt_file = self._get_latest_checkpoint(\n","                self.netD_ckpt_dir)\n","\n","        # Log hyperparameters for experiments\n","        self.params = {\n","            'log_dir': self.log_dir,\n","            'num_steps': self.num_steps,\n","            'batch_size': self.dataloader.batch_size,\n","            'n_dis': self.n_dis,\n","            'lr_decay': self.lr_decay,\n","            'optD': optD.__repr__(),\n","            'optG': optG.__repr__(),\n","            'save_steps': self.save_steps,\n","        }\n","        self._log_params(self.params)\n","\n","        # Device for hosting model and data\n","        if not self.device:\n","            self.device = torch.device(\n","                'cuda:0' if torch.cuda.is_available() else \"cpu\")\n","\n","        # Ensure model and data are in the same device\n","        for net in [self.netD, self.netG]:\n","            if net.device != self.device:\n","                net.to(self.device)\n","#         for net in [self.netD, self.netG]:\n","#             if next(net.parameters()).device != self.device:\n","#                 net.to(self.device)\n","\n","    def _log_params(self, params):\n","        \"\"\"\n","        Takes the argument options to save into a json file.\n","        \"\"\"\n","        params_file = os.path.join(self.log_dir, 'params.json')\n","\n","        # Check for discrepancy with previous training config.\n","        if os.path.exists(params_file):\n","            check = load_from_json(params_file)\n","\n","            if params != check:\n","                diffs = []\n","                for k in params:\n","                    if k in check and params[k] != check[k]:\n","                        diffs.append('{}: Expected {} but got {}.'.format(\n","                            k, check[k], params[k]))\n","\n","                diff_string = '\\n'.join(diffs)\n","                raise ValueError(\n","                    \"Current hyperparameter configuration is different from previously:\\n{}\"\n","                    .format(diff_string))\n","\n","        write_to_json(params, params_file)\n","\n","    def _get_latest_checkpoint(self, ckpt_dir):\n","        \"\"\"\n","        Given a checkpoint dir, finds the checkpoint with the latest training step.\n","        \"\"\"\n","        def _get_step_number(k):\n","            \"\"\"\n","            Helper function to get step number from checkpoint files.\n","            \"\"\"\n","            search = re.search(r'(\\d+)_steps', k)\n","\n","            if search:\n","                return int(search.groups()[0])\n","            else:\n","                return -float('inf')\n","\n","        if not os.path.exists(ckpt_dir):\n","            return None\n","\n","        files = os.listdir(ckpt_dir)\n","        if len(files) == 0:\n","            return None\n","\n","        ckpt_file = max(files, key=lambda x: _get_step_number(x))\n","\n","        return os.path.join(ckpt_dir, ckpt_file)\n","\n","    def _fetch_data(self, iter_dataloader):\n","        \"\"\"\n","        Fetches the next set of data and refresh the iterator when it is exhausted.\n","        Follows python EAFP, so no iterator.hasNext() is used.\n","        \"\"\"\n","        try:\n","            real_batch = next(iter_dataloader)\n","        except StopIteration:\n","            iter_dataloader = iter(self.dataloader)\n","            real_batch = next(iter_dataloader)\n","\n","        real_batch = real_batch[0].to(self.device)\n","\n","        return real_batch\n","\n","    def _restore_models_and_step(self):\n","        \"\"\"\n","        Restores model and optimizer checkpoints and ensures global step is in sync.\n","        \"\"\"\n","        global_step_D = global_step_G = 0\n","\n","        if self.netD_ckpt_file and os.path.exists(self.netD_ckpt_file):\n","            print(\"INFO: Restoring checkpoint for D...\")\n","            global_step_D = self.netD.restore_checkpoint(\n","                ckpt_file=self.netD_ckpt_file, optimizer=self.optD)\n","\n","        if self.netG_ckpt_file and os.path.exists(self.netG_ckpt_file):\n","            print(\"INFO: Restoring checkpoint for G...\")\n","            global_step_G = self.netG.restore_checkpoint(\n","                ckpt_file=self.netG_ckpt_file, optimizer=self.optG)\n","\n","        if global_step_G != global_step_D:\n","            raise ValueError('G and D Networks are out of sync.')\n","        else:\n","            global_step = global_step_G  # Restores global step\n","\n","        return global_step\n","\n","    def _save_model_checkpoints(self, global_step):\n","        \"\"\"\n","        Saves both discriminator and generator checkpoints.\n","        \"\"\"\n","        self.netG.save_checkpoint(directory=self.netG_ckpt_dir,\n","                                  global_step=global_step,\n","                                  optimizer=self.optG)\n","\n","        self.netD.save_checkpoint(directory=self.netD_ckpt_dir,\n","                                  global_step=global_step,\n","                                  optimizer=self.optD)\n","\n","\n","\n","\n","\n","    def plot_everything(self, generated_data, gen_err, critic_err):\n","        def compute_psd(data, fs, nperseg=256, noverlap=None):\n","            \"\"\"\n","            Compute Power Spectral Density (PSD) using the Welch method.\n","\n","            Parameters:\n","                data (array): EEG data array with shape (n_channels, n_samples).\n","                fs (float): Sampling frequency.\n","                nperseg (int): Length of each segment for PSD estimation.\n","                noverlap (int): Number of overlapping samples between segments.\n","\n","            Returns:\n","                freqs (array): Frequency values.\n","                psd (array): Power Spectral Density values.\n","            \"\"\"\n","            n_channels, n_samples = data.shape\n","            psd = np.zeros((n_channels, nperseg // 2 + 1))\n","\n","            for ch_idx in range(n_channels):\n","                f, Pxx = plt.psd(data[ch_idx], Fs=fs, NFFT=256, noverlap=128, window=np.hanning(256), scale_by_freq=True)\n","                # Add a small epsilon to avoid zero values\n","                psd[ch_idx] = Pxx + 1e-10\n","\n","            return f, psd\n","\n","        def average_across_arrays(generated_data):\n","            return generated_data.mean(dim=0)\n","\n","        # Set the sampling frequency\n","        fs = 160.0\n","\n","        generated_data = generated_data.detach()\n","\n","        # plotting generated data\n","        values = generated_data[0, 0, :]\n","        plt.plot(values.tolist())\n","        plt.show()\n","\n","        # plotting PSD\n","        averaged_data = average_across_arrays(generated_data)\n","        freqs, psd = compute_psd(averaged_data, fs)\n","        plt.figure(figsize=(10, 6))  # Add this line to create a single figure\n","        for ch_idx in range(1):\n","            plt.semilogy(freqs, psd[ch_idx], label=f'Channel {ch_idx + 1}')\n","        plt.xlabel('Frequency (Hz)')\n","        plt.ylabel('Power/Frequency (dB/Hz)')\n","        plt.show()\n","\n","        # plotting G vs D losses\n","        plt.figure(figsize=(10,5))\n","        plt.title(\"Generator and Discriminator Loss During Training\")\n","        plt.plot(gen_err,label=\"Generator\")\n","        plt.plot(critic_err,label=\"Critic\")\n","        plt.xlabel(\"iterations\")\n","        plt.ylabel(\"Loss\")\n","        plt.legend()\n","        plt.show()\n","\n","\n","\n","\n","    def train(self):\n","        \"\"\"\n","        Runs the training pipeline with all given parameters in Trainer.\n","        \"\"\"\n","        # Restore models\n","        global_step = self._restore_models_and_step()\n","        print(\"INFO: Starting training from global step {}...\".format(\n","            global_step))\n","\n","        try:\n","            start_time = time.time()\n","\n","            # Iterate through data\n","            iter_dataloader = iter(self.dataloader)\n","            while global_step < self.num_steps:\n","                log_data = MetricLog()  # log data for tensorboard\n","\n","                # -------------------------\n","                #   One Training Step\n","                # -------------------------\n","                # Update n_dis times for D\n","                for i in range(self.n_dis):\n","                    real_batch = self._fetch_data(iter_dataloader=iter_dataloader)\n","\n","                    # ------------------------\n","                    #   Update D Network\n","                    # -----------------------\n","                    log_data = self.netD.train_step(real_batch=real_batch,\n","                                                    netG=self.netG,\n","                                                    optD=self.optD,\n","                                                    log_data=log_data,\n","                                                    global_step=global_step,\n","                                                    device=self.device)\n","\n","                    # -----------------------\n","                    #   Update G Network\n","                    # -----------------------\n","                    # Update G, but only once.\n","                    if i == (self.n_dis - 1):\n","                        log_data = self.netG.train_step(\n","                            real_batch=real_batch,\n","                            netD=self.netD,\n","                            optG=self.optG,\n","                            global_step=global_step,\n","                            log_data=log_data,\n","                            device=self.device)\n","\n","                # --------------------------------\n","                #   Update Training Variables\n","                # -------------------------------\n","                global_step += 1\n","\n","                log_data = self.scheduler.step(log_data=log_data,\n","                                               global_step=global_step)\n","\n","                # -------------------------\n","                #   Logging and Metrics\n","                # -------------------------\n","                if global_step % self.log_steps == 0:\n","                    self.logger.write_summaries(log_data=log_data,\n","                                                global_step=global_step)\n","\n","                if global_step % self.print_steps == 0:\n","                    curr_time = time.time()\n","                    self.logger.print_log(global_step=global_step,\n","                                          log_data=log_data,\n","                                          time_taken=(curr_time - start_time) /\n","                                          self.print_steps)\n","                    start_time = curr_time\n","\n","                # if global_step % self.vis_steps == 0:\n","                #     self.logger.vis_images(netG=self.netG,\n","                #                            global_step=global_step)\n","\n","                if global_step % self.save_steps == 0:\n","                    print(\"INFO: Saving checkpoints...\")\n","                    self._save_model_checkpoints(global_step)\n","\n","            print(\"INFO: Saving final checkpoints...\")\n","            self._save_model_checkpoints(global_step)\n","\n","        except KeyboardInterrupt:\n","            print(\"INFO: Saving checkpoints from keyboard interrupt...\")\n","            self._save_model_checkpoints(global_step)\n","\n","        finally:\n","            self.logger.close_writers()\n","\n","        print(\"INFO: Training Ended.\")\n","\n","\"\"\"\n","Implementation of BaseModel.\n","\"\"\"\n","import os\n","from abc import ABC, abstractmethod\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","class BaseModel(nn.Module, ABC):\n","    r\"\"\"\n","    BaseModel with basic functionalities for checkpointing and restoration.\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","\n","    @abstractmethod\n","    def forward(self, x):\n","        pass\n","\n","    @property\n","    def device(self):\n","        return next(self.parameters()).device\n","\n","    def restore_checkpoint(self, ckpt_file, optimizer=None):\n","        r\"\"\"\n","        Restores checkpoint from a pth file and restores optimizer state.\n","\n","        Args:\n","            ckpt_file (str): A PyTorch pth file containing model weights.\n","            optimizer (Optimizer): A vanilla optimizer to have its state restored from.\n","\n","        Returns:\n","            int: Global step variable where the model was last checkpointed.\n","        \"\"\"\n","        if not ckpt_file:\n","            raise ValueError(\"No checkpoint file to be restored.\")\n","\n","        try:\n","            ckpt_dict = torch.load(ckpt_file)\n","        except RuntimeError:\n","            ckpt_dict = torch.load(ckpt_file,\n","                                   map_location=lambda storage, loc: storage)\n","\n","        # Restore model weights\n","        self.load_state_dict(ckpt_dict['model_state_dict'])\n","\n","        # Restore optimizer status if existing. Evaluation doesn't need this\n","        if optimizer:\n","            optimizer.load_state_dict(ckpt_dict['optimizer_state_dict'])\n","\n","        # Return global step\n","        return ckpt_dict['global_step']\n","\n","    def save_checkpoint(self,\n","                        directory,\n","                        global_step,\n","                        optimizer=None,\n","                        name=None):\n","        r\"\"\"\n","        Saves checkpoint at a certain global step during training. Optimizer state\n","        is also saved together.\n","\n","        Args:\n","            directory (str): Path to save checkpoint to.\n","            global_step (int): The global step variable during training.\n","            optimizer (Optimizer): Optimizer state to be saved concurrently.\n","            name (str): The name to save the checkpoint file as.\n","\n","        Returns:\n","            None\n","        \"\"\"\n","        # Create directory to save to\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","\n","        # Build checkpoint dict to save.\n","        ckpt_dict = {\n","            'model_state_dict':\n","            self.state_dict(),\n","            'optimizer_state_dict':\n","            optimizer.state_dict() if optimizer is not None else None,\n","            'global_step':\n","            global_step\n","        }\n","\n","        # Save the file with specific name\n","        if name is None:\n","            name = \"{}_{}_steps.pth\".format(\n","                os.path.basename(directory),  # netD or netG\n","                global_step)\n","\n","        torch.save(ckpt_dict, os.path.join(directory, name))\n","\n","    def count_params(self):\n","        r\"\"\"\n","        Computes the number of parameters in this model.\n","\n","        Args: None\n","\n","        Returns:\n","            int: Total number of weight parameters for this model.\n","            int: Total number of trainable parameters for this model.\n","\n","        \"\"\"\n","        num_total_params = sum(p.numel() for p in self.parameters())\n","        num_trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","        return num_total_params, num_trainable_params\n","\n","\"\"\"\n","Implementation of residual blocks for discriminator and generator.\n","We follow the official SNGAN Chainer implementation as closely as possible:\n","https://github.com/pfnet-research/sngan_projection\n","\"\"\"\n","import math\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class GBlock(nn.Module):\n","    r\"\"\"\n","    Residual block for generator.\n","\n","    Uses linear (rather than nearest) interpolation, and align_corners\n","    set to False. This is as per how torchvision does upsampling, as seen in:\n","    https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/_utils.py\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        hidden_channels (int): The channel size of intermediate feature maps.\n","        upsample (bool): If True, upsamples the input feature map.\n","        num_classes (int): If more than 0, uses conditional batch norm instead.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 hidden_channels=None,\n","                 upsample=False,\n","                 num_classes=0,\n","                 spectral_norm=False):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.hidden_channels = hidden_channels if hidden_channels is not None else out_channels\n","        self.learnable_sc = in_channels != out_channels or upsample\n","        self.upsample = upsample\n","        self.padding = nn.ReflectionPad1d((4,4))\n","\n","        self.num_classes = num_classes\n","        self.spectral_norm = spectral_norm\n","\n","        # Build the layers\n","        # Note: Can't use something like self.conv = SNConv1d to save code length\n","        # this results in somehow spectral norm working worse consistently.\n","        self.c1 = nn.Conv1d(self.in_channels,\n","                            self.hidden_channels,\n","                            3,\n","                            1)\n","        self.c2 = nn.Conv1d(self.hidden_channels,\n","                            self.out_channels,\n","                            3,\n","                            1)\n","\n","        if self.num_classes == 0:\n","            self.b1 = nn.BatchNorm1d(self.in_channels)\n","            self.b2 = nn.BatchNorm1d(self.hidden_channels)\n","\n","        self.activation = nn.LeakyReLU(0.2)\n","\n","        nn.init.normal_(self.c1.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.c2.weight.data, 0.0, 0.02)\n","\n","        # Shortcut layer\n","        if self.learnable_sc:\n","            self.c_sc = nn.Conv1d(in_channels,\n","                                  out_channels,\n","                                  1,\n","                                  1,\n","                                  padding=0)\n","\n","            nn.init.normal_(self.c_sc.weight.data, 0.0, 0.02)\n","\n","    def _upsample_conv(self, x, conv):\n","        r\"\"\"\n","        Helper function for performing convolution after upsampling.\n","        \"\"\"\n","        return conv(\n","            F.interpolate(x,\n","                          scale_factor=2,\n","                          mode='linear',\n","                          align_corners=False))\n","\n","    def _residual(self, x):\n","        r\"\"\"\n","        Helper function for feedforwarding through main layers.\n","        \"\"\"\n","        h = x\n","        h = self._upsample_conv(h, self.c1) if self.upsample else self.c1(h)\n","        h = self.b1(h)\n","        h = self.activation(h)\n","#         h = self.c2(h)\n","#         h = self.b2(h)\n","#         h = self.activation(h)\n","\n","        return h\n","\n","    # def _residual_conditional(self, x, y):\n","    #     r\"\"\"\n","    #     Helper function for feedforwarding through main layers, including conditional BN.\n","    #     \"\"\"\n","    #     h = x\n","    #     h = self.b1(h, y)\n","    #     h = self.activation(h)\n","    #     h = self._upsample_conv(h, self.c1) if self.upsample else self.c1(h)\n","    #     h = self.b2(h, y)\n","    #     h = self.activation(h)\n","    #     h = self.c2(h)\n","\n","    #     return h\n","\n","    def _shortcut(self, x):\n","        r\"\"\"\n","        Helper function for feedforwarding through shortcut layers.\n","        \"\"\"\n","        if self.learnable_sc:\n","            x = self._upsample_conv(\n","                x, self.c_sc) if self.upsample else self.c_sc(x)\n","            return x\n","        else:\n","            return x\n","\n","    def forward(self, x, y=None):\n","        r\"\"\"\n","        Residual block feedforward function.\n","        \"\"\"\n","        if y is None:\n","            return self._residual(x)\n","        #+ self._shortcut(x)\n","\n","        else:\n","            return self._residual_conditional(x, y)\n","        #+ self._shortcut(x)\n","\n","\n","class DBlock(nn.Module):\n","    \"\"\"\n","    Residual block for discriminator.\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        hidden_channels (int): The channel size of intermediate feature maps.\n","        downsample (bool): If True, downsamples the input feature map.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size,\n","                 stride=1,\n","                 padding=0,\n","                 hidden_channels=None,\n","                 downsample=False,\n","                 spectral_norm=True,\n","                 reflectionPad = False):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.hidden_channels = hidden_channels if hidden_channels is not None else in_channels\n","        self.downsample = downsample\n","        self.learnable_sc = (in_channels != out_channels) or downsample\n","        self.spectral_norm = spectral_norm\n","        self.kernel_size = kernel_size\n","        self.padding = nn.ReflectionPad1d((padding,padding))\n","        self.reflectionPad = reflectionPad\n","\n","        # Build the layers\n","        self.c1 = nn.Conv1d(self.in_channels, self.out_channels, self.kernel_size, stride)\n","        self.c2 = nn.Conv1d(self.hidden_channels, self.out_channels, self.kernel_size, stride)\n","\n","        self.activation = nn.LeakyReLU(0.2)\n","\n","        nn.init.normal_(self.c1.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.c2.weight.data, 0.0, 0.02)\n","\n","        # Shortcut layer\n","        if self.learnable_sc:\n","            self.c_sc = nn.Conv1d(in_channels, out_channels, 1, 1, 0)\n","\n","            nn.init.normal_(self.c_sc.weight.data, 0.0, 0.02)\n","\n","    def _residual(self, x):\n","        \"\"\"\n","        Helper function for feedforwarding through main layers.\n","        \"\"\"\n","        h = x\n","        h = self.c1(h)\n","        h = self.activation(h)\n","        if self.downsample:\n","            h = F.avg_pool1d(h, 2)\n","#         h = self.c2(h)\n","#         h = self.activation(h)\n","        \n","        return h\n","\n","    def _shortcut(self, x):\n","        \"\"\"\n","        Helper function for feedforwarding through shortcut layers.\n","        \"\"\"\n","        if self.learnable_sc:\n","            x = self.c_sc(x)\n","            return F.avg_pool1d(x, 2) if self.downsample else x\n","\n","        else:\n","            return x\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Residual block feedforward function.\n","        \"\"\"\n","        return self._residual(x)\n","    #+ self._shortcut(x)\n","\n","\n","class DBlockOptimized(nn.Module):\n","    \"\"\"\n","    Optimized residual block for discriminator. This is used as the first residual block,\n","    where there is a definite downsampling involved. Follows the official SNGAN reference implementation\n","    in chainer.\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, spectral_norm=True):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.spectral_norm = spectral_norm\n","\n","        # Build the layers\n","        self.c1 = nn.Conv1d(self.in_channels, self.out_channels, 1, 1, 0)\n","        self.c2 = nn.Conv1d(self.out_channels, self.out_channels, 1, 1, 0)\n","        self.c_sc = nn.Conv1d(self.in_channels, self.out_channels, 1, 1, 0)\n","\n","        self.activation = nn.LeakyReLU(0.2)\n","\n","        nn.init.normal_(self.c1.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.c2.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.c_sc.weight.data, 0.0, 0.02)\n","\n","    def _residual(self, x):\n","        \"\"\"\n","        Helper function for feedforwarding through main layers.\n","        \"\"\"\n","        h = x\n","        h = self.c1(h)\n","        h = self.activation(h)\n","        h = self.c2(h)\n","        h = F.avg_pool1d(h, 2)\n","        return h\n","\n","    def _shortcut(self, x):\n","        \"\"\"\n","        Helper function for feedforwarding through shortcut layers.\n","        \"\"\"\n","        return self.c_sc(F.avg_pool1d(x, 2))\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Residual block feedforward function.\n","        \"\"\"\n","        return self._residual(x)\n","    #+ self._shortcut(x)\n","\n","\"\"\"\n","ResBlocks for WGAN-GP.\n","\"\"\"\n","import torch.nn as nn\n","import torch.functional as F\n","\n","\n","class GBlock(GBlock):\n","    r\"\"\"\n","    Residual block for generator.\n","    Modifies original resblock definitions with small changes.\n","\n","    Uses linear (rather than nearest) interpolation, and align_corners\n","    set to False. This is as per how torchvision does upsampling, as seen in:\n","    https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/_utils.py\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        hidden_channels (int): The channel size of intermediate feature maps.\n","        upsample (bool): If True, upsamples the input feature map.\n","        num_classes (int): If more than 0, uses conditional batch norm instead.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 hidden_channels=None,\n","                 upsample=False,\n","                 num_classes=0,\n","                 spectral_norm=False,\n","                 **kwargs):\n","        super().__init__(in_channels=in_channels,\n","                         out_channels=out_channels,\n","                         hidden_channels=hidden_channels,\n","                         upsample=upsample,\n","                         num_classes=num_classes,\n","                         spectral_norm=spectral_norm,\n","                         **kwargs)\n","\n","        # Redefine shortcut layer without act.\n","        if self.learnable_sc:\n","            self.c_sc = nn.Conv1d(self.in_channels,\n","                                  self.out_channels,\n","                                  1,\n","                                  1,\n","                                  padding=0)\n","\n","\n","class DBlock(DBlock):\n","    r\"\"\"\n","    Residual block for discriminator.\n","\n","    Modifies original resblock definition by including layer norm and removing\n","    act for shortcut. Convs are LN-ReLU-Conv. See official TF code:\n","    https://github.com/igul222/improved_wgan_training/blob/master/gan_cifar_resnet.py#L105\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        hidden_channels (int): The channel size of intermediate feature maps.\n","        downsample (bool): If True, downsamples the input feature map.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size,\n","                 stride=1,\n","                 padding=0,\n","                 hidden_channels=None,\n","                 downsample=False,\n","                 spectral_norm=False,\n","                 reflectionPad=False,\n","                 **kwargs):\n","        super().__init__(in_channels=in_channels,\n","                         out_channels=out_channels,\n","                         kernel_size=kernel_size,\n","                         stride=stride,\n","                         padding=padding,\n","                         hidden_channels=hidden_channels,\n","                         downsample=downsample,\n","                         spectral_norm=spectral_norm,\n","                         reflectionPad=reflectionPad,\n","                         **kwargs)\n","\n","        # Redefine shortcut layer without act.\n","        # TODO: Maybe can encapsulate defining of learnable sc in a fn\n","        # then override it later? Might be cleaner.\n","        if self.learnable_sc:\n","            self.c_sc = nn.Conv1d(self.in_channels, self.out_channels, 1, 1, 0)\n","\n","        self.norm1 = None\n","        self.norm2 = None\n","\n","    # TODO: Verify again. Interestingly, LN has no effect on FID. Not using LN\n","    # has almost no difference in FID score.\n","    # def residual(self, x):\n","    #     r\"\"\"\n","    #     Helper function for feedforwarding through main layers.\n","    #     \"\"\"\n","    #     if self.norm1 is None:\n","    #         self.norm1 = nn.LayerNorm(\n","    #             [self.in_channels, x.shape[2], x.shape[3]])\n","\n","    #     h = x\n","    #     h = self.norm1(h)\n","    #     h = self.activation(h)\n","    #     h = self.c1(h)\n","\n","    #     if self.norm2 is None:\n","    #         self.norm2 = nn.LayerNorm(\n","    #             [self.hidden_channels, h.shape[2], h.shape[3]])\n","\n","    #     h = self.norm2(h)\n","    #     h = self.activation(h)\n","    #     h = self.c2(h)\n","    #     if self.downsample:\n","    #         h = F.avg_pool2d(h, 2)\n","\n","    #     return h\n","\n","\n","class DBlockOptimized(DBlockOptimized):\n","    r\"\"\"\n","    Optimized residual block for discriminator.\n","\n","    Does not have any normalisation. See official TF Code:\n","    https://github.com/igul222/improved_wgan_training/blob/master/gan_cifar_resnet.py#L139\n","\n","    Attributes:\n","        in_channels (int): The channel size of input feature map.\n","        out_channels (int): The channel size of output feature map.\n","        spectral_norm (bool): If True, uses spectral norm for convolutional layers.\n","    \"\"\"\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 spectral_norm=False,\n","                 **kwargs):\n","        super().__init__(in_channels=in_channels,\n","                         out_channels=out_channels,\n","                         spectral_norm=spectral_norm,\n","                         **kwargs)\n","\n","        # Redefine shortcut layer\n","        self.c_sc = nn.Conv1d(self.in_channels, self.out_channels, 1, 1, 0)\n","\n","\"\"\"\n","Base class implementation of WGAN-GP.\n","\"\"\"\n","import torch\n","from torch import autograd\n","\n","\"\"\"\n","Implementation of Base GAN models.\n","\"\"\"\n","import torch\n","\n","class BaseGenerator(BaseModel):\n","    r\"\"\"\n","    Base class for a generic unconditional generator model.\n","\n","    Attributes:\n","        nz (int): Noise dimension for upsampling.\n","        ngf (int): Variable controlling generator feature map sizes.\n","        sequence_length (int): Starting width for upsampling generator output to a signal.\n","        loss_type (str): Name of loss to use for GAN loss.\n","    \"\"\"\n","    def __init__(self, nz, ngf, sequence_length, loss_type, **kwargs):\n","        super().__init__(**kwargs)\n","        self.nz = nz\n","        self.ngf = ngf\n","        self.sequence_length = sequence_length\n","        self.loss_type = loss_type\n","\n","    def generate_signals(self, num_signals, device=None):\n","        r\"\"\"\n","        Generates num_signals randomly.\n","\n","        Args:\n","            num_signals (int): Number of signals to generate\n","            device (torch.device): Device to send signals to.\n","\n","        Returns:\n","            Tensor: A batch of generated signals.\n","        \"\"\"\n","        if device is None:\n","            device = self.device\n","\n","        noise = torch.randn((num_signals, self.nz), device=device)\n","        fake_signals = self.forward(noise)\n","\n","        return fake_signals\n","\n","    def compute_gan_loss(self, output):\n","        r\"\"\"\n","        Computes GAN loss for generator.\n","\n","        Args:\n","            output (Tensor): A batch of output logits from the discriminator of shape (N, 1).\n","\n","        Returns:\n","            Tensor: A batch of GAN losses for the generator.\n","        \"\"\"\n","        # Compute loss and backprop\n","        if self.loss_type == \"gan\":\n","            errG = minimax_loss_gen(output)\n","\n","        elif self.loss_type == \"ns\":\n","            errG = ns_loss_gen(output)\n","\n","        elif self.loss_type == \"hinge\":\n","            errG = hinge_loss_gen(output)\n","\n","        elif self.loss_type == \"wasserstein\":\n","            errG = wasserstein_loss_gen(output)\n","\n","        else:\n","            raise ValueError(\"Invalid loss_type {} selected.\".format(self.loss_type))\n","\n","        return errG\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netD,\n","                   optG,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for G.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real signals of shape (N, C, H, W). Used for obtaining current batch size.\n","            netD (nn.Module): Discriminator model for obtaining losses.\n","            optG (Optimizer): Optimizer for updating generator's parameters.\n","            log_data (dict): A dict mapping name to values for logging uses.\n","            device (torch.device): Device to use for running the model.\n","            global_step (int): Variable to sync training, logging and checkpointing. Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            Returns MetricLog object containing updated logging variables after 1 training step.\n","\n","        \"\"\"\n","        self.zero_grad()\n","\n","        # Get only batch size from real batch\n","        batch_size = real_batch[0].shape[0]\n","\n","        # Produce fake signals\n","        fake_signals = self.generate_signals(num_signals=batch_size, device=device)\n","\n","        # Compute output logit of D thinking signal real\n","        output = netD(fake_signals)\n","\n","        # Compute loss\n","        errG = self.compute_gan_loss(output=output)\n","\n","        # Backprop and update gradients\n","        errG.backward()\n","        optG.step()\n","\n","        # Log statistics\n","        log_data.add_metric('errG', errG, group='loss')\n","\n","        return log_data\n","\n","\n","class BaseDiscriminator(BaseModel):\n","    r\"\"\"\n","    Base class for a generic unconditional discriminator model.\n","\n","    Attributes:\n","        ndf (int): Variable controlling discriminator feature map sizes.\n","        loss_type (str): Name of loss to use for GAN loss.\n","    \"\"\"\n","    def __init__(self, ndf, loss_type, **kwargs):\n","        super().__init__(**kwargs)\n","        self.ndf = ndf\n","        self.loss_type = loss_type\n","\n","    def compute_gan_loss(self, output_real, output_fake):\n","        r\"\"\"\n","        Computes GAN loss for discriminator.\n","\n","        Args:\n","            output_real (Tensor): A batch of output logits of shape (N, 1) from real signals.\n","            output_fake (Tensor): A batch of output logits of shape (N, 1) from fake signals.\n","\n","        Returns:\n","            errD (Tensor): A batch of GAN losses for the discriminator.\n","        \"\"\"\n","        # Compute loss for D\n","        if self.loss_type == \"gan\" or self.loss_type == \"ns\":\n","            errD = minimax_loss_dis(output_fake=output_fake, output_real=output_real)\n","\n","        elif self.loss_type == \"hinge\":\n","            errD = hinge_loss_dis(output_fake=output_fake, output_real=output_real)\n","\n","        elif self.loss_type == \"wasserstein\":\n","            errD = wasserstein_loss_dis(output_fake=output_fake, output_real=output_real)\n","\n","        else:\n","            raise ValueError(\"Invalid loss_type selected.\")\n","\n","        return errD\n","\n","    def compute_probs(self, output_real, output_fake):\n","        r\"\"\"\n","        Computes probabilities from real/fake signals logits.\n","\n","        Args:\n","            output_real (Tensor): A batch of output logits of shape (N, 1) from real signals.\n","            output_fake (Tensor): A batch of output logits of shape (N, 1) from fake signals.\n","\n","        Returns:\n","            tuple: Average probabilities of real/fake signal considered as real for the batch.\n","        \"\"\"\n","        D_x = torch.sigmoid(output_real).mean().item()\n","        D_Gz = torch.sigmoid(output_fake).mean().item()\n","\n","        return D_x, D_Gz\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netG,\n","                   optD,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for D.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real signals of shape (N, C, H, W).\n","            loss_type (str): Name of loss to use for GAN loss.\n","            netG (nn.Module): Generator model for obtaining fake signals.\n","            optD (Optimizer): Optimizer for updating discriminator's parameters.\n","            device (torch.device): Device to use for running the model.\n","            log_data (dict): A dict mapping name to values for logging uses.\n","            global_step (int): Variable to sync training, logging and checkpointing.\n","                Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            MetricLog: Returns MetricLog object containing updated logging variables after 1 training step.\n","        \"\"\"\n","        self.zero_grad()\n","        real_signals, real_labels = real_batch\n","        batch_size = real_signals.shape[0]  # Match batch sizes for last iter\n","\n","        # Produce logits for real signals\n","        output_real = self.forward(real_signals)\n","\n","        # Produce fake signals\n","        fake_signals = netG.generate_signals(num_signals=batch_size, device=device).detach()\n","\n","        # Produce logits for fake signals\n","        output_fake = self.forward(fake_signals)\n","\n","        # Compute loss for D\n","        errD = self.compute_gan_loss(output_real=output_real, output_fake=output_fake)\n","\n","        # Backprop and update gradients\n","        errD.backward()\n","        optD.step()\n","\n","        # Compute probabilities\n","        D_x, D_Gz = self.compute_probs(output_real=output_real, output_fake=output_fake)\n","\n","        # Log statistics for D once out of loop\n","        log_data.add_metric('errD', errD.item(), group='loss')\n","        log_data.add_metric('D(x)', D_x, group='prob')\n","        log_data.add_metric('D(G(z))', D_Gz, group='prob')\n","\n","        return log_data\n","\n","\n","class WGANGPBaseGenerator(BaseGenerator):\n","    r\"\"\"\n","    ResNet backbone generator for WGAN-GP.\n","\n","    Attributes:\n","        nz (int): Noise dimension for upsampling.\n","        ngf (int): Variable controlling generator feature map sizes.\n","        sequence_length (int): Starting width for upsampling generator output to an signal.\n","        loss_type (str): Name of loss to use for GAN loss.\n","    \"\"\"\n","    def __init__(self,\n","                 nz,\n","                 ngf,\n","                 sequence_length,\n","                 loss_type='wasserstein',\n","                 **kwargs):\n","        super().__init__(nz=nz,\n","                         ngf=ngf,\n","                         sequence_length=sequence_length,\n","                         loss_type=loss_type,\n","                         **kwargs)\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netD,\n","                   optG,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for G.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real signals of shape (N, C, L).\n","                Used for obtaining current batch size.\n","            netD (nn.Module): Discriminator model for obtaining losses.\n","            optG (Optimizer): Optimizer for updating generator's parameters.\n","            log_data (MetricLog): An object to add custom metrics for visualisations.\n","            device (torch.device): Device to use for running the model.\n","            global_step (int): Variable to sync training, logging and checkpointing.\n","                Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            MetricLog: Returns MetricLog object containing updated logging variables after 1 training step.\n","\n","        \"\"\"\n","        self.zero_grad()\n","\n","        # Get only batch size from real batch\n","        batch_size = real_batch[0].shape[0]\n","\n","        # Produce fake signals\n","        fake_signals = self.generate_signals(num_signals=batch_size, device=device)\n","\n","        # Compute output logit of D thinking signal real\n","        output = netD(fake_signals)\n","\n","        # Compute loss\n","        errG = self.compute_gan_loss(output)\n","\n","        # Backprop and update gradients\n","        errG.backward()\n","        optG.step()\n","\n","        # Log statistics\n","        log_data.add_metric('errG', errG, group='loss')\n","\n","        return log_data\n","\n","\n","class WGANGPBaseDiscriminator(BaseDiscriminator):\n","    r\"\"\"\n","    ResNet backbone discriminator for WGAN-GP.\n","\n","    Attributes:\n","        ndf (int): Variable controlling discriminator feature map sizes.\n","        loss_type (str): Name of loss to use for GAN loss.\n","        gp_scale (float): Lamda parameter for gradient penalty.\n","    \"\"\"\n","    def __init__(self, ndf, loss_type='wasserstein', gp_scale=10.0, **kwargs):\n","        super().__init__(ndf=ndf, loss_type=loss_type, **kwargs)\n","        self.gp_scale = gp_scale\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netG,\n","                   optD,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for D.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real signals of shape (N, C, L).\n","            netG (nn.Module): Generator model for obtaining fake signals.\n","            optD (Optimizer): Optimizer for updating discriminator's parameters.\n","            device (torch.device): Device to use for running the model.\n","            log_data (MetricLog): An object to add custom metrics for visualisations.\n","            global_step (int): Variable to sync training, logging and checkpointing.\n","                Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            MetricLog: Returns MetricLog object containing updated logging variables after 1 training step.\n","\n","        \"\"\"\n","        self.zero_grad()\n","\n","        # Produce real signals\n","        real_signals = real_batch\n","        batch_size = real_signals.shape[0]  # Match batch sizes for last iter\n","\n","        # Produce fake signals\n","        fake_signals = netG.generate_signals(num_signals=batch_size, device=device).detach()\n","\n","        # Produce logits for real and fake signals\n","        output_real = self.forward(real_signals)\n","        output_fake = self.forward(fake_signals)\n","\n","        # Compute losses\n","        errD = self.compute_gan_loss(output_real=output_real,\n","                                     output_fake=output_fake)\n","\n","        errD_GP = self.compute_gradient_penalty_loss(real_signals=real_signals,\n","                                                     fake_signals=fake_signals,\n","                                                     gp_scale=self.gp_scale)\n","\n","        # Backprop and update gradients\n","        errD_total = errD + errD_GP\n","        errD_total.backward()\n","        optD.step()\n","\n","        # Compute probabilities\n","        D_x, D_Gz = self.compute_probs(output_real=output_real,\n","                                       output_fake=output_fake)\n","\n","        log_data.add_metric('errD', errD, group='loss')\n","        log_data.add_metric('D(x)', D_x, group='prob')\n","        log_data.add_metric('D(G(z))', D_Gz, group='prob')\n","\n","        return log_data\n","\n","    def compute_gradient_penalty_loss(self,\n","                                      real_signals,\n","                                      fake_signals,\n","                                      gp_scale=10.0):\n","        r\"\"\"\n","        Computes gradient penalty loss, as based on:\n","        https://github.com/jalola/improved-wgan-pytorch/blob/master/gan_train.py\n","\n","        Args:\n","            real_signals (Tensor): A batch of real signals of shape (N, 3, L). // TODO: make num of channels configurable\n","            fake_signals (Tensor): A batch of fake signals of shape (N, 3, L).\n","            gp_scale (float): Gradient penalty lamda parameter.\n","\n","        Returns:\n","            Tensor: Scalar gradient penalty loss.\n","        \"\"\"\n","        # Obtain parameters\n","        N, _, L = real_signals.shape\n","        device = real_signals.device\n","\n","        # Randomly sample some alpha between 0 and 1 for interpolation\n","        # where alpha is of the same shape for elementwise multiplication.\n","        alpha = torch.rand(N, 1)\n","        alpha = alpha.expand(N, int(real_signals.nelement() / N)).contiguous()\n","        alpha = alpha.view(N, 1, L)\n","        alpha = alpha.to(device)\n","\n","        # Obtain interpolates on line between real/fake signals.\n","        interpolates = alpha * real_signals.detach() \\\n","            + ((1 - alpha) * fake_signals.detach())\n","        interpolates = interpolates.to(device)\n","        interpolates.requires_grad_(True)\n","\n","        # Get gradients of interpolates\n","        disc_interpolates = self.forward(interpolates)\n","        gradients = autograd.grad(outputs=disc_interpolates,\n","                                  inputs=interpolates,\n","                                  grad_outputs=torch.ones(\n","                                      disc_interpolates.size()).to(device),\n","                                  create_graph=True,\n","                                  retain_graph=True,\n","                                  only_inputs=True)[0]\n","        gradients = gradients.view(gradients.size(0), -1)\n","\n","        # Compute GP loss\n","        gradient_penalty = (\n","            (gradients.norm(2, dim=1) - 1)**2).mean() * gp_scale\n","\n","        return gradient_penalty\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import os\n","import sklearn\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn.functional as F\n","from torch.fft import rfft, irfft\n","from torch.nn.functional import normalize\n","from scipy.signal import welch\n","from scipy import signal\n","import math\n","from torch.autograd import Variable\n","\n","def compute_psd(data, fs, nperseg=256, noverlap=None):\n","    \"\"\"\n","    Compute Power Spectral Density (PSD) using the Welch method.\n","\n","    Parameters:\n","        data (array): EEG data array with shape (n_channels, n_samples).\n","        fs (float): Sampling frequency.\n","        nperseg (int): Length of each segment for PSD estimation.\n","        noverlap (int): Number of overlapping samples between segments.\n","\n","    Returns:\n","        freqs (array): Frequency values.\n","        psd (array): Power Spectral Density values.\n","    \"\"\"\n","    n_channels, n_samples = data.shape\n","    psd = np.zeros((n_channels, nperseg // 2 + 1))\n","\n","    for ch_idx in range(n_channels):\n","        f, Pxx = plt.psd(data[ch_idx].cpu(), Fs=fs, NFFT=256, noverlap=128, window=np.hanning(256), scale_by_freq=True)\n","        # Add a small epsilon to avoid zero values\n","        psd[ch_idx] = Pxx + 1e-10\n","\n","    return f, psd\n","\n","\n","def average_across_arrays(generated_data):\n","    return generated_data.mean(dim=0)\n","\n","def plot_everything(generated_data, gen_err, critic_err):\n","    generated_data = generated_data.detach()\n","\n","    # plotting generated data\n","    values = generated_data[0, 0, :]\n","    plt.plot(values.tolist())\n","    plt.show()\n","\n","    # plotting PSD\n","    psd = get_fft_feature_train(generated_data.cpu())\n","    plt.plot(psd[0,0])\n","    plt.show()\n","#     averaged_data = average_across_arrays(generated_data)\n","#     freqs, psd = compute_psd(averaged_data, 160.0)\n","#     plt.figure(figsize=(10, 6))  # Add this line to create a single figure\n","#     for ch_idx in range(1):\n","#         plt.semilogy(freqs, psd[ch_idx], label=f'Channel {ch_idx + 1}')\n","#     plt.xlabel('Frequency (Hz)')\n","#     plt.ylabel('Power/Frequency (dB/Hz)')\n","#     plt.show()\n","\n","    # plotting G vs D losses\n","    plt.figure(figsize=(10,5))\n","    plt.title(\"Generator and Discriminator Loss During Training\")\n","    plt.plot(gen_err,label=\"Generator\")\n","    plt.plot(critic_err,label=\"Critic\")\n","    plt.xlabel(\"iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()\n","\n","\n","class Generator(WGANGPBaseGenerator):\n","    r\"\"\"\n","    Base class for a generic unconditional generator model.\n","    ResNet backbone generator for SNGAN.\n","\n","    Attributes:\n","        nz (int): Noise dimension for upsampling.\n","        ngf (int): Variable controlling generator feature map sizes.\n","        bottom_width (int): Starting width for upsampling generator output to an image.\n","        loss_type (str): Name of loss to use for GAN loss.\n","    \"\"\"\n","    def __init__(self, **kwargs):\n","        super().__init__(nz=500, ngf=150, sequence_length=54)\n","        self.errG_array = []\n","        self.count = 0\n","\n","        # Build the layers\n","        self.l1 = nn.Linear(self.nz, self.sequence_length * self.ngf)\n","        self.block1 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block2 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.block3 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block4 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.block5 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block6 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.block7 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block8 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.block9 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block10 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.block11 = GBlock(self.ngf, self.ngf, upsample=True)\n","        self.block12 = GBlock(self.ngf, self.ngf, upsample=False)\n","        self.c13 = nn.Conv1d(self.ngf, 64, 1, 1, 0)\n","        self.end = nn.Linear(3204, 3152)\n","\n","        # Initialise the weights\n","        nn.init.normal_(self.l1.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.c13.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.end.weight.data, 0.0, 0.02)\n","\n","    def forward(self, x):\n","        r\"\"\"\n","        Feedforwards a batch of noise vectors into a batch of fake images.\n","\n","        Args:\n","            x (Tensor): A batch of noise vectors of shape (N, nz).\n","\n","        Returns:\n","            Tensor: A batch of fake images of shape (N, C, L).\n","        \"\"\"\n","        h = self.l1(x)\n","        h = h.view(x.shape[0], self.ngf, self.sequence_length)\n","        h = self.block1(h)\n","        h = self.block2(h)\n","        h = self.block3(h)\n","        h = self.block4(h)\n","        h = self.block5(h)\n","        h = self.block6(h)\n","        h = self.block7(h)\n","        h = self.block8(h)\n","        h = self.block9(h)\n","        h = self.block10(h)\n","        h = self.block11(h)\n","        h = self.block12(h)\n","        h = self.c13(h)\n","        h = self.end(h)\n","        return h\n","\n","    def generate_signals(self, num_signals, device=None):\n","        r\"\"\"\n","        Generates num_signals randomly.\n","\n","        Args:\n","            num_signals (int): Number of signals to generate\n","            device (torch.device): Device to send images to.\n","\n","        Returns:\n","            Tensor: A batch of generated images.\n","        \"\"\"\n","        if device is None:\n","            device = self.device\n","\n","        noise = torch.randn((num_signals, self.nz), device=device)\n","        fake_signals = self.forward(noise)\n","\n","        return fake_signals\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netD,\n","                   optG,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for G.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real images of shape (N, C, L).\n","                Used for obtaining current batch size.\n","            netD (nn.Module): Discriminator model for obtaining losses.\n","            optG (Optimizer): Optimizer for updating generator's parameters.\n","            log_data (dict): A dict mapping name to values for logging uses.\n","            device (torch.device): Device to use for running the model.\n","            global_step (int): Variable to sync training, logging and checkpointing.\n","                Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            Returns MetricLog object containing updated logging variables after 1 training step.\n","\n","        \"\"\"\n","        batch_size = real_batch[0].shape[0]  # Get only batch size from real batch\n","\n","        # Produce logits for fake signals\n","        fake_signals = self.generate_signals(num_signals=batch_size, device=device)\n","        out_fake = netD(fake_signals)\n","\n","        self.zero_grad()\n","\n","        # Backprop and update gradients\n","        errG = self.compute_gan_loss(out_fake)\n","        errG.backward()\n","        optG.step()\n","\n","        # Log statistics\n","        self.errG_array.append(errG.item())\n","        if (self.count != 0 and self.count % 100 == 0):\n","            print(errG.item(), 'gen')\n","        self.count += 1\n","        log_data.add_metric('errG', errG.item(), group='loss')\n","        return log_data\n","\n","    \n","def get_fft_feature_train(data, nperseg=256, noverlap=128, channels=64):\n","    all_fft = []\n","    device = data.device\n","\n","    # Create window function\n","    window = torch.hann_window(nperseg, dtype=torch.float, device=device)\n","\n","    for x in data:\n","        avg_psds_db = []\n","        \n","        for ch in range(channels):\n","            chx = x[ch]\n","\n","            # Separate x into overlapping segments\n","            x_segs = chx.unfold(0, nperseg, nperseg - noverlap)\n","\n","            # Apply window function to each segment\n","            windowed_segs = x_segs * window\n","\n","            # Compute power spectral density for each windowed segment\n","            seg_psds = torch.fft.rfft(windowed_segs, dim=1)\n","            seg_psds = torch.abs(seg_psds)**2\n","\n","            # Average PSDs over all segments\n","            avg_psds = torch.mean(seg_psds, axis=0)\n","\n","            # Convert to decibels\n","            avg_psds_db.append(torch.log10(avg_psds + 1e-10))\n","\n","        avg_psds_db = torch.stack(avg_psds_db)\n","        all_fft.append(avg_psds_db)\n","\n","    all_fft = torch.stack(all_fft, dim=0).to(device)\n","    return all_fft\n","\n","\n","\n","\n","class Discriminator(WGANGPBaseDiscriminator):\n","    def __init__(self, **kwargs):\n","        super().__init__(ndf=150)\n","        self.count = 0\n","        self.errD_array = []\n","\n","        self.sblock1 = DBlock(64, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock2 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.sblock3 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock4 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.sblock5 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock6 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.sblock7 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock8 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.sblock9 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock10 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.sblock11 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=False, reflectionPad=True)\n","        self.sblock12 = DBlock(self.ndf, self.ndf, kernel_size=3, stride=1, padding=0, downsample=True, reflectionPad=True)\n","        self.c = nn.Conv1d(self.ndf, 64, 1, 1, 0)\n","        self.end = nn.Linear(45, 1)\n","        \n","        nn.init.normal_(self.c.weight.data, 0.0, 0.02)\n","        nn.init.normal_(self.end.weight.data, 0.0, 0.02)\n","\n","    def forward(self, x):\n","        x = x.float()\n","        h = self.sblock1(x)\n","        h = self.sblock2(h)\n","        h = self.sblock3(h)\n","        h = self.sblock4(h)\n","        h = self.sblock5(h)\n","        h = self.sblock6(h)\n","        h = self.sblock7(h)\n","        h = self.sblock8(h)\n","        h = self.sblock9(h)\n","        h = self.sblock10(h)\n","        h = self.sblock11(h)\n","        h = self.sblock12(h)\n","        h = self.c(h)\n","        h = self.end(h)\n","        return h.view(h.shape[0], 64)\n","\n","    def train_step(self,\n","                   real_batch,\n","                   netG,\n","                   optD,\n","                   log_data,\n","                   device=None,\n","                   global_step=None,\n","                   **kwargs):\n","        r\"\"\"\n","        Takes one training step for D.\n","\n","        Args:\n","            real_batch (Tensor): A batch of real images of shape (N, C, H, W).\n","            loss_type (str): Name of loss to use for GAN loss.\n","            netG (nn.Module): Generator model for obtaining fake images.\n","            optD (Optimizer): Optimizer for updating discriminator's parameters.\n","            device (torch.device): Device to use for running the model.\n","            log_data (dict): A dict mapping name to values for logging uses.\n","            global_step (int): Variable to sync training, logging and checkpointing.\n","                Useful for dynamic changes to model amidst training.\n","\n","        Returns:\n","            MetricLog: Returns MetricLog object containing updated logging variables after 1 training step.\n","        \"\"\"\n","        batch_size = real_batch.shape[0] # Match batch sizes for last iter\n","\n","        # Produce logits for real signals\n","        real_signals = real_batch\n","        out_real = self.forward(real_signals)\n","\n","        # Produce logits for fake signals\n","        fake_signals = netG.generate_signals(num_signals=batch_size, device=device).detach()\n","        out_fake = self.forward(fake_signals)\n","\n","        # Reset the gradients to zero\n","        optD.zero_grad()\n","\n","        # Backprop and update gradients\n","        errD = self.compute_gan_loss(output_real=out_real, output_fake=out_fake)\n","        errD_GP = self.compute_gradient_penalty_loss(real_signals=real_signals, fake_signals=fake_signals)\n","\n","        errD_total = errD + errD_GP\n","        errD_total.backward()\n","        optD.step()\n","\n","\n","        # Log statistics\n","        if (self.count != 0 and self.count % 5 == 0):\n","            self.errD_array.append(errD_total.item())\n","            log_data.add_metric('errD', errD.item(), group='loss')\n","            log_data.add_metric('errD_GP', errD_GP.item(), group='loss')\n","        if (self.count != 0 and self.count % 500 == 0):\n","            print(errD_total.item(), 'disc')\n","        if (self.count % 5000 == 0):\n","            plot_everything(fake_signals, netG.errG_array, self.errD_array)\n","        self.count += 1\n","\n","        return log_data\n","\n","    def compute_gradient_penalty_loss(self,\n","                                      real_signals,\n","                                      fake_signals,\n","                                      gp_scale=10.0):\n","        r\"\"\"\n","        Computes gradient penalty loss, as based on:\n","        https://github.com/jalola/improved-wgan-pytorch/blob/master/gan_train.py\n","\n","        Args:\n","            real_signals (Tensor): A batch of real signals of shape (N, 1, L). // TODO: make num of channels configurable\n","            fake_signals (Tensor): A batch of fake signals of shape (N, 1, L).\n","            gp_scale (float): Gradient penalty lamda parameter.\n","\n","        Returns:\n","            Tensor: Scalar gradient penalty loss.\n","        \"\"\"\n","        # Obtain parameters\n","        N, _, L = real_signals.shape\n","        device = real_signals.device\n","\n","        # Randomly sample some alpha between 0 and 1 for interpolation\n","        # where alpha is of the same shape for elementwise multiplication.\n","        alpha = torch.rand(N, 1)\n","        alpha = alpha.expand(N, int(real_signals.nelement() / N)).contiguous()\n","        alpha = alpha.view(N, 64, L)  # TODO: MAKE CHANNEL VARIABLE\n","        alpha = alpha.to(device)\n","\n","        # Obtain interpolates on line between real/fake signals.\n","        interpolates = alpha * real_signals.detach() \\\n","            + ((1 - alpha) * fake_signals.detach())\n","        interpolates = interpolates.to(device)\n","        interpolates.requires_grad_(True)\n","\n","        # Get gradients of interpolates\n","        disc_interpolates = self.forward(interpolates)\n","        gradients = autograd.grad(outputs=disc_interpolates,\n","                                  inputs=interpolates,\n","                                  grad_outputs=torch.ones(\n","                                      disc_interpolates.size()).to(device),\n","                                  create_graph=True,\n","                                  retain_graph=True,\n","                                  only_inputs=True)[0]\n","        gradients = gradients.view(gradients.size(0), -1)\n","\n","        # Compute GP loss\n","        gradient_penalty = (\n","            (gradients.norm(2, dim=1) - 1)**2).mean() * gp_scale\n","\n","        return gradient_penalty\n","\n","\n","    \n","    \n","data = np.load('../training/normalized-training-closed-64ch.npy')\n","\n","# Data handling objects\n","if torch.cuda.is_available():\n","  print(\"hello GPU\")\n","else:\n","  print(\"sadge\")\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","dataloader = DataLoader(\n","    TensorDataset(data),\n","    batch_size=32,\n","    shuffle=True\n",")\n","\n","def weights_init(model):\n","    for m in model.modules():\n","      if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.BatchNorm1d)):\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","netD = Discriminator()\n","netG = Generator()\n","\n","weights_init(netD)\n","weights_init(netG)\n","\n","if torch.cuda.device_count() > 1:\n","    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n","    netD = nn.DataParallel(netD)\n","    netG = nn.DataParallel(netG)\n","\n","netD.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","netG.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","optD = optim.Adam(netD.parameters(), 0.0001, (0.5, 0.99))\n","optG = optim.Adam(netG.parameters(), 0.0001, (0.5, 0.99))\n","\n","\n","# Start training\n","trainer = Trainer(\n","    netD=netD.module,\n","    netG=netG.module,\n","    optD=optD,\n","    optG=optG,\n","    n_dis=5,\n","    num_steps=1000000,\n","    lr_decay='linear',\n","    dataloader=dataloader,\n","    save_steps=2000,\n","    print_steps=100,\n","    log_dir='/model',\n","    device=device)\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
